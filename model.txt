AlbertForSequenceClassification(
  (albert): AlbertModel(
    (embeddings): AlbertEmbeddings(
      (word_embeddings): Embedding(21128, 128, padding_idx=0)
      (position_embeddings): Embedding(512, 128)
      (token_type_embeddings): Embedding(2, 128)
      (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (encoder): AlbertTransformer(
      (embedding_hidden_mapping_in): Linear(in_features=128, out_features=312, bias=True)
      (albert_layer_groups): ModuleList(
        (0): AlbertLayerGroup(
          (albert_layers): ModuleList(
            (0): AlbertLayer(
              (full_layer_layer_norm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)
              (attention): AlbertSdpaAttention(
                (query): Linear(in_features=312, out_features=312, bias=True)
                (key): Linear(in_features=312, out_features=312, bias=True)
                (value): Linear(in_features=312, out_features=312, bias=True)
                (attention_dropout): Dropout(p=0.0, inplace=False)
                (output_dropout): Dropout(p=0.0, inplace=False)
                (dense): Linear(in_features=312, out_features=312, bias=True)
                (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)
              )
              (ffn): Linear(in_features=312, out_features=1248, bias=True)
              (ffn_output): Linear(in_features=1248, out_features=312, bias=True)
              (activation): GELUActivation()
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
      )
    )
    (pooler): Linear(in_features=312, out_features=312, bias=True)
    (pooler_activation): Tanh()
  )
  (dropout): Dropout(p=0.1, inplace=False)
  (classifier): Linear(in_features=312, out_features=2, bias=True)
)


albert.embeddings.word_embeddings.weight
albert.embeddings.position_embeddings.weight
albert.embeddings.token_type_embeddings.weight
albert.embeddings.LayerNorm.weight
albert.embeddings.LayerNorm.bias
albert.encoder.embedding_hidden_mapping_in.weight
albert.encoder.embedding_hidden_mapping_in.bias
albert.encoder.albert_layer_groups.0.albert_layers.0.full_layer_layer_norm.weight
albert.encoder.albert_layer_groups.0.albert_layers.0.full_layer_layer_norm.bias
albert.encoder.albert_layer_groups.0.albert_layers.0.attention.query.weight
albert.encoder.albert_layer_groups.0.albert_layers.0.attention.query.bias
albert.encoder.albert_layer_groups.0.albert_layers.0.attention.key.weight
albert.encoder.albert_layer_groups.0.albert_layers.0.attention.key.bias
albert.encoder.albert_layer_groups.0.albert_layers.0.attention.value.weight
albert.encoder.albert_layer_groups.0.albert_layers.0.attention.value.bias
albert.encoder.albert_layer_groups.0.albert_layers.0.attention.dense.weight
albert.encoder.albert_layer_groups.0.albert_layers.0.attention.dense.bias
albert.encoder.albert_layer_groups.0.albert_layers.0.attention.LayerNorm.weight
albert.encoder.albert_layer_groups.0.albert_layers.0.attention.LayerNorm.bias
albert.encoder.albert_layer_groups.0.albert_layers.0.ffn.weight
albert.encoder.albert_layer_groups.0.albert_layers.0.ffn.bias
albert.encoder.albert_layer_groups.0.albert_layers.0.ffn_output.weight
albert.encoder.albert_layer_groups.0.albert_layers.0.ffn_output.bias
albert.pooler.weight
albert.pooler.bias
classifier.weight
classifier.bias